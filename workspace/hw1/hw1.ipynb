{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a68d851-7775-45ca-b537-954461c8de24",
   "metadata": {},
   "source": [
    "# ДОМАШНЕЕ ЗАДАНИЕ № 1. Spark RDD API\n",
    "---\n",
    "**Дисциплина:** Методы обработки больших данных  \n",
    "**Студент:** Голдышев Д.М. (goldyshev02@mail.ru)  \n",
    "**Группа:** ИУ6-31М  \n",
    "\n",
    "## Задание 3. Косинусное сходство между фильмами\n",
    "---\n",
    "### Цель\n",
    "Вычислить косинусное сходство между рейтингами фильмов, используя **только стандартные операции RDD API**.\n",
    "\n",
    "### Задачи\n",
    "1. Вычислить косинусное сходство между рейтингами фильмов.\n",
    "2. Для фильма с `movieId = 589` сформировать RDD со значениями сходства с остальными фильмами.\n",
    "3. Добавить наименования фильмов.\n",
    "4. Вывести топ-10 наиболее похожих фильмов.\n",
    "\n",
    "### Данные\n",
    "Используется датасет [MovieLens (ml-latest-small)](http://files.grouplens.org/datasets/movielens/ml-latest-small.zip):\n",
    "- `ratings.csv` — рейтинги пользователей (userId, movieId, rating, timestamp)\n",
    "- `movies.csv` — справочник фильмов (movieId, title, genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dad3d90-dc44-4b2a-ab05-65eef8a5c6e8",
   "metadata": {},
   "source": [
    "## Шаг 1. Импорт зависимостей и конфигурация\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6be191f5-a065-4fb9-9144-ce4f5ad594a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import errno\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import math\n",
    "import csv\n",
    "import io\n",
    "from pyspark import SparkContext, SparkConf \n",
    "\n",
    "TARGET_MOVIE_ID = 589 # ID фильма, для которого ищем похожие\n",
    "TOP_N = 10 # Количество похожих фильмов для вывода\n",
    "\n",
    "DATA_PATH = \"/app/data/ml-latest-small\" # Путь к директории с данными MovieLens\n",
    "RATINGS_PATH = f\"{DATA_PATH}/ratings.csv\" # Путь к данным с рейтингами\n",
    "MOVIES_PATH = f\"{DATA_PATH}/movies.csv\" # Путь к данным с фильмами\n",
    "OUTPUT_PATH = \"./hw1_rdd_cosine_results.csv\" # Путь для сохранения результатов\n",
    "\n",
    "MIN_COMMON_USERS_INITIAL = 10 # Начальный порог минимального количества общих пользователей\n",
    "MIN_COMMON_USERS_FLOOR = 2 # Минимально допустимый порог\n",
    "THRESHOLD_STEP = 2 # Шаг уменьшения порога при fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bf6801-f3c8-4f98-a9c4-dee81e46e8f0",
   "metadata": {},
   "source": [
    "### Проверка существования данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46452422-cb7a-4c7d-a400-2bcf381ace1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файлы, необходимые для работы, найдены и читаются.\n"
     ]
    }
   ],
   "source": [
    "def check_file(path: str):\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"{path}: файл не найден\")\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.read(1)  # пробное чтение\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"{path}: файл существует, но не читается: {e}\")\n",
    "\n",
    "try:\n",
    "    check_file(RATINGS_PATH)\n",
    "    check_file(MOVIES_PATH)\n",
    "    print(\"Файлы, необходимые для работы, найдены и читаются.\")\n",
    "except Exception as e:\n",
    "    print(\"Ошибка при проверке файлов:\")\n",
    "    print(e)\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b876f76-933f-453a-98b1-7f8b80ca8ac6",
   "metadata": {},
   "source": [
    "### Проверка возможности сохранения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b4b3654-d536-4f13-8d97-c015f7928d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Можно сохранять результаты в указанные директории\n"
     ]
    }
   ],
   "source": [
    "def ensure_output_path(path: str) -> Path:\n",
    "    p = Path(path).expanduser()\n",
    "    if p.exists() and p.is_dir():\n",
    "        dir_path = p\n",
    "    else:\n",
    "        if str(p).endswith(os.sep) or (not p.exists() and p.suffix == \"\"):\n",
    "            dir_path = p\n",
    "        else:\n",
    "            dir_path = p.parent\n",
    "    if not str(dir_path):\n",
    "        dir_path = Path(\".\")\n",
    "    try:\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    except PermissionError as e:\n",
    "        raise PermissionError(f\"{dir_path}: нет прав на создание директории: {e}\")\n",
    "    except OSError as e:\n",
    "        raise OSError(f\"{dir_path}: не удалось создать директорию: {e}\")\n",
    "    if not os.access(dir_path, os.W_OK):\n",
    "        raise PermissionError(f\"{dir_path}: нет прав на запись в директорию\")\n",
    "    try:\n",
    "        with tempfile.NamedTemporaryFile(dir=dir_path, delete=True) as tmp:\n",
    "            tmp.write(b\"test\")\n",
    "            tmp.flush()\n",
    "    except OSError as e:\n",
    "        raise OSError(f\"{dir_path}: невозможно записать временный файл: {e}\")\n",
    "    return dir_path\n",
    "\n",
    "try:\n",
    "    ensure_output_path(OUTPUT_PATH)\n",
    "    print(\"Можно сохранять результаты в указанные директории\")\n",
    "except Exception as e:\n",
    "    print(\"Ошибка при проверке директорий для записи результатов:\")\n",
    "    print(e)\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97003292-d651-4a2a-b6f3-e74f701dda45",
   "metadata": {},
   "source": [
    "## Шаг 2. Функции парсинга данных\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79d5f1c-21fa-4793-83f0-c2ed57731c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_rating(line):\n",
    "    \"\"\"\n",
    "    Парсинг строки ratings.csv -> (userId, movieId, rating)\n",
    "    \"\"\"\n",
    "    reader = csv.reader(io.StringIO(line))\n",
    "    parts = next(reader)\n",
    "    # Возвращаем userId, movieId, rating (игнорируем parts[3] - timestamp)\n",
    "    return (int(parts[0]), int(parts[1]), float(parts[2]))\n",
    "\n",
    "def parse_movie(line):\n",
    "    \"\"\"\n",
    "    Парсинг строки movies.csv -> (movieId, title)\n",
    "    \"\"\"\n",
    "    reader = csv.reader(io.StringIO(line))\n",
    "    parts = next(reader)\n",
    "    # Возвращаем movieId, title (игнорируем parts[2] - genres)\n",
    "    return (int(parts[0]), parts[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cec8693-88d1-472f-904b-b8007323b76b",
   "metadata": {},
   "source": [
    "## Шаг 3. Инициализация SparkContext\n",
    "---\n",
    "SparkContext управляет подключением к кластеру Spark и является обязательным для любых RDD-операций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1094fc-4aea-4586-9e07-1187eed31d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/10 23:17:14 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://092d5b0bdf55:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW1_CosineSimilarity_RDD</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=HW1_CosineSimilarity_RDD>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate(\n",
    "    SparkConf()\n",
    "        .setAppName(\"HW1_CosineSimilarity_RDD\")\n",
    "        .setMaster(\"local[*]\")\n",
    ")\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e051de8-9a45-40ab-8973-e165bc20e4fa",
   "metadata": {},
   "source": [
    "## Шаг 4. Загрузка и предобработка данных\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48fbf6b-65ae-496a-8140-0e67f0b583ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено рейтингов: 100836\n",
      "Загружено фильмов: 9742\n"
     ]
    }
   ],
   "source": [
    "# Загрузка рейтингов\n",
    "ratings_raw = sc.textFile(RATINGS_PATH)\n",
    "header_ratings = ratings_raw.first()\n",
    "ratings_rdd = ratings_raw \\\n",
    "    .filter(lambda line: line != header_ratings) \\\n",
    "    .map(parse_rating) \\\n",
    "    .cache() # Cохраняем RDD в памяти для повторного использования\n",
    "\n",
    "# Загрузка фильмов\n",
    "movies_raw = sc.textFile(MOVIES_PATH)\n",
    "header_movies = movies_raw.first()\n",
    "movies_rdd = movies_raw \\\n",
    "    .filter(lambda line: line != header_movies) \\\n",
    "    .map(parse_movie)\n",
    "\n",
    "# Собираем словарь фильмов (т.к. датасет небольшой)\n",
    "movies_dict = dict(movies_rdd.collect())\n",
    "# Создаём broadcast-переменную для передачи на все worker-узлы\n",
    "movies_broadcast = sc.broadcast(movies_dict)\n",
    "\n",
    "# Выводим статистику загрузки\n",
    "print(f\"Загружено рейтингов: {ratings_rdd.count()}\")\n",
    "print(f\"Загружено фильмов: {len(movies_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6149f5a9-71b3-429d-a190-5079dc4a5a1d",
   "metadata": {},
   "source": [
    "## Шаг 5. Подготовка данных о рейтингах пользователей\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6daf3fb-172c-4091-b377-21aa0989168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_movie = ratings_rdd.map(\n",
    "    lambda x: (\n",
    "        x[0],          # ключ: userId\n",
    "        (x[1], x[2])   # значение: (movieId, rating)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3834d-8562-4d89-a2a7-e9b1b7759320",
   "metadata": {},
   "source": [
    "## Шаг 6. Генерация пар фильмов\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1469e2bf-c33c-4956-953f-a1b65a28284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-join по userId, чтобы получить пары фильмов, оценённых одним пользователем\n",
    "movie_pairs = (\n",
    "    user_movie\n",
    "        # join по ключу userId\n",
    "        .join(user_movie)\n",
    "        # Убираем дубликаты пар фильмов\n",
    "        .filter(lambda x: x[1][0][0] < x[1][1][0])\n",
    "        # Приводим к формату: ((movie1, movie2), (rating1, rating2))\n",
    "        .map(lambda x: (\n",
    "            # ключ: пара идентификаторов фильмов (movie1, movie2)\n",
    "            (x[1][0][0], x[1][1][0]),\n",
    "            # значение: соответствующие оценки (rating1, rating2)\n",
    "            (x[1][0][1], x[1][1][1])\n",
    "        ))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf61edd-8d86-4adf-b866-2366370cbf2b",
   "metadata": {},
   "source": [
    "## Шаг 7. Вычисление косинусного сходства\n",
    "---\n",
    "#### Формула косинусного сходства\n",
    "Для двух фильмов A и B:\n",
    "$$\n",
    "\\text{sim}(A, B) = \\frac{\\sum_{u} r_{uA} \\cdot r_{uB}}{\\sqrt{\\sum_{u} r_{uA}^2} \\cdot \\sqrt{\\sum_{u} r_{uB}^2}}\n",
    "$$\n",
    "где $r_{uA}$ — рейтинг пользователя $u$ для фильма $A$, суммирование по пользователям, оценившим оба фильма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44890959-6117-4f19-b3bc-efe779502214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вычислено пар сходства: 13157672\n",
      "Первые 10 пар сходства:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/10 23:19:38 WARN BlockManager: Task 18 already completed, not releasing lock for rdd_20_0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(125, 357, 0.9116377679037143, 7),\n",
       " (162, 2336, 0.9307253886204377, 7),\n",
       " (588, 3386, 0.9787962339515168, 15),\n",
       " (898, 3044, 0.9938837346736188, 2),\n",
       " (902, 904, 0.9873303331142156, 17),\n",
       " (937, 2145, 0.9978801059658184, 2),\n",
       " (1198, 1892, 0.9595213389890941, 8),\n",
       " (1199, 1895, 0.9070543032310491, 4),\n",
       " (2843, 4239, 0.9952226187595397, 3),\n",
       " (260, 4878, 0.9524073755949048, 72)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Начальное значение аккумулятора: (dot_product, norm1_sq, norm2_sq, count)\n",
    "# dot_product — скалярное произведение векторов рейтингов\n",
    "# norm1_sq — сумма квадратов рейтингов первого фильма\n",
    "# norm2_sq — сумма квадратов рейтингов второго фильма  \n",
    "# count — количество общих пользователей\n",
    "ZERO_VALUE = (0.0, 0.0, 0.0, 0)\n",
    "\n",
    "def seq_op(acc, val):\n",
    "    \"\"\"\n",
    "    Обновление аккумулятора новым значением пары рейтингов.\n",
    "    Args:\n",
    "        acc: текущий аккумулятор (dot, norm1_sq, norm2_sq, count)\n",
    "        val: новое значение (rating1, rating2)\n",
    "    Returns:\n",
    "        обновлённый аккумулятор\n",
    "    \"\"\"\n",
    "    r1, r2 = val\n",
    "    return (\n",
    "        acc[0] + r1 * r2,      # dot_product += r1 * r2\n",
    "        acc[1] + r1 * r1,      # norm1_sq += r1^2\n",
    "        acc[2] + r2 * r2,      # norm2_sq += r2^2\n",
    "        acc[3] + 1             # count += 1\n",
    "    )\n",
    "\n",
    "def comb_op(acc1, acc2):\n",
    "    \"\"\"\n",
    "    Объединяет два частичных результата.\n",
    "    Args:\n",
    "        acc1, acc2: два аккумулятора для объединения\n",
    "    Returns:\n",
    "        объединённый аккумулятор\n",
    "    \"\"\"\n",
    "    return (\n",
    "        acc1[0] + acc2[0],  # суммируем dot_product\n",
    "        acc1[1] + acc2[1],  # суммируем norm1_sq\n",
    "        acc1[2] + acc2[2],  # суммируем norm2_sq\n",
    "        acc1[3] + acc2[3]   # суммируем count\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_final_similarity(acc):\n",
    "    \"\"\"\n",
    "    Вычисление финального значения косинусного сходства из аккумулятора.\n",
    "    Args:\n",
    "        acc: финальный аккумулятор\n",
    "    Returns:\n",
    "        (similarity, count) [или (0.0, count) при делении на ноль]\n",
    "    \"\"\"\n",
    "    dot, norm1_sq, norm2_sq, count = acc\n",
    "    \n",
    "    # Защита от деления на ноль\n",
    "    if count == 0 or norm1_sq == 0 or norm2_sq == 0:\n",
    "        return (0.0, count)\n",
    "    \n",
    "    # Косинусное сходство = dot / (||v1|| * ||v2||)\n",
    "    similarity = dot / (math.sqrt(norm1_sq) * math.sqrt(norm2_sq))\n",
    "    return (similarity, count)\n",
    "\n",
    "\n",
    "# Вычисление сходства\n",
    "similarities = movie_pairs \\\n",
    "    .aggregateByKey(ZERO_VALUE, seq_op, comb_op) \\\n",
    "    .mapValues(compute_final_similarity) \\\n",
    "    .map(lambda x: (x[0][0], x[0][1], x[1][0], x[1][1])) \\\n",
    "    .cache()\n",
    "# Структура результата: (movie1, movie2, similarity, common_users_count)\n",
    "\n",
    "print(f\"Вычислено пар сходства: {similarities.count()}\")\n",
    "print(\"Первые 10 пар сходства:\")\n",
    "similarities.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e7485-8a4a-472a-b091-0457b2d0585c",
   "metadata": {},
   "source": [
    "## Шаг 8. Фильтрация для целевого фильма\n",
    "---\n",
    "При вычислении косинусного сходства между двумя фильмами важно учитывать **статистическую надёжность оценки**. Если два фильма имеют всего несколько общих пользователей, то их косинусное сходство может быть случайным и не отражать реальной похожести. Например, если оба фильма оценили только 2 человека, и оба поставили одинаковые оценки, сходство будет равно 1.0 — но это совершенно не означает, что фильмы действительно похожи.\n",
    "\n",
    "Поэтому, для повышения статистической значимости сходства и для предотвращения попадания в формируемый топ случайно высоких коэффициентов, было решено **формировать результирующий список похожих фильмов только из пар, где количество общих пользователей превышает заданный порог**. В случае недостатка результатов порог постепенно снижается, но остаётся в пределах \"разумного минимума\", гарантирующего хотя бы базовую достоверность результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a6be36-a603-47a1-8007-1f8fa8307cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Поиск похожих фильмов для movieId = 589\n",
      "----------------------------------------\n",
      "Попытка с порогом общих пользователей >= 10...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:>                                                         (0 + 4) / 4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 10 фильмов\n",
      "\n",
      "Используемый порог: 10 общих пользователей\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "def get_similar_movies(similarities_rdd, target_id, min_common, top_n):\n",
    "    \"\"\"\n",
    "    Фильтрует и возвращает топ похожих фильмов для целевого фильма.\n",
    "    Args:\n",
    "        similarities_rdd: RDD с (movie1, movie2, similarity, count)\n",
    "        target_id: ID целевого фильма\n",
    "        min_common: минимальное количество общих пользователей\n",
    "        top_n: количество результатов\n",
    "    Returns:\n",
    "        список [(other_movie_id, similarity, common_count), ...]\n",
    "    \"\"\"\n",
    "    # Фильтруем пары, где участвует целевой фильм\n",
    "    filtered = similarities_rdd \\\n",
    "        .filter(lambda x: x[0] == target_id or x[1] == target_id) \\\n",
    "        .map(lambda x: (\n",
    "            # Извлекаем ID похожего фильма\n",
    "            x[1] if x[0] == target_id else x[0],\n",
    "            x[2],  # similarity\n",
    "            x[3]   # common_users_count\n",
    "        )) \\\n",
    "        .filter(lambda x: x[2] >= min_common)  # Фильтр по минимуму общих пользователей\n",
    "    \n",
    "    # Сортируем по убыванию сходства и берём top_n\n",
    "    return filtered.sortBy(lambda x: -x[1]).take(top_n)\n",
    "\n",
    "current_threshold = MIN_COMMON_USERS_INITIAL\n",
    "top_similar = []\n",
    "\n",
    "print(f\"\\nПоиск похожих фильмов для movieId = {TARGET_MOVIE_ID}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Уменьшаем порог, пока не найдём достаточно результатов\n",
    "while current_threshold >= MIN_COMMON_USERS_FLOOR:\n",
    "    print(f\"Попытка с порогом общих пользователей >= {current_threshold}...\")\n",
    "    top_similar = get_similar_movies(\n",
    "        similarities, \n",
    "        TARGET_MOVIE_ID, \n",
    "        current_threshold, \n",
    "        TOP_N\n",
    "    )\n",
    "    if len(top_similar) >= TOP_N:\n",
    "        # Нашли достаточно результатов\n",
    "        print(f\"Найдено {len(top_similar)} фильмов\")\n",
    "        break\n",
    "    else:\n",
    "        # Не хватает результатов — уменьшаем порог\n",
    "        print(f\"  Найдено только {len(top_similar)}, уменьшаем порог...\")\n",
    "        current_threshold -= THRESHOLD_STEP\n",
    "\n",
    "# Проверка, если даже с минимальным порогом недостаточно результатов\n",
    "if len(top_similar) < TOP_N:\n",
    "    print(f\"Внимание: найдено только {len(top_similar)} похожих фильмов\")\n",
    "    print(f\"(даже с минимальным порогом {MIN_COMMON_USERS_FLOOR})\")\n",
    "\n",
    "# Получаем название целевого фильма\n",
    "movies_local = movies_broadcast.value\n",
    "target_title = movies_local.get(TARGET_MOVIE_ID, \"Unknown\")\n",
    "\n",
    "print(f\"\\nИспользуемый порог: {current_threshold} общих пользователей\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289a09c-e825-48b3-89a3-e3045e54297c",
   "metadata": {},
   "source": [
    "## Шаг 9. Вывод и сохранение результатов\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f369a5-94db-437b-a2d9-c09149093741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Топ-10 фильмов, похожих на:\n",
      "  [589] Terminator 2: Judgment Day (1991)\n",
      "======================================================================\n",
      "Rank  MovieID  Similarity   Common   Title\n",
      "----------------------------------------------------------------------\n",
      "1     1223     0.995822     11       Grand Day Out with Wallace and Gromit, A (1989)\n",
      "2     82461    0.995054     11       Tron: Legacy (2010)\n",
      "3     7482     0.994651     12       Enter the Dragon (1973)\n",
      "4     119145   0.994354     17       Kingsman: The Secret Service (2015)\n",
      "5     33660    0.993120     10       Cinderella Man (2005)\n",
      "6     6586     0.992872     10       American Wedding (American Pie 3) (2003)\n",
      "7     27831    0.992559     14       Layer Cake (2004)\n",
      "8     1231     0.992442     12       Right Stuff, The (1983)\n",
      "9     86190    0.991156     10       Hanna (2011)\n",
      "10    4865     0.989886     12       From Hell (2001)\n",
      "\n",
      "Результаты сохранены: ./hw1_rdd_cosine_results.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(f\"Топ-{len(top_similar)} фильмов, похожих на:\")\n",
    "print(f\"  [{TARGET_MOVIE_ID}] {target_title}\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Rank':<5} {'MovieID':<8} {'Similarity':<12} {'Common':<8} Title\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Список для сохранения в файл\n",
    "results = []\n",
    "\n",
    "# Выводим результаты в консоль\n",
    "for rank, (movie_id, sim, count) in enumerate(top_similar, 1):\n",
    "    title = movies_local.get(movie_id, \"Unknown\")\n",
    "    print(f\"{rank:<5} {movie_id:<8} {sim:<12.6f} {count:<8} {title}\")\n",
    "    results.append(f\"{rank},{movie_id},{sim:.6f},{count},{title}\")\n",
    "\n",
    "# Сохраняем результаты в файл\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:    \n",
    "    # Заголовок CSV\n",
    "    f.write(\"rank,movieId,similarity,common_users,title\\n\")\n",
    "    # Записываем все строки результатов\n",
    "    for line in results:\n",
    "        f.write(line + \"\\n\")\n",
    "\n",
    "print(f\"\\nРезультаты сохранены: {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba5fd28-365b-4e10-a4e5-96d72e94b107",
   "metadata": {},
   "source": [
    "## Шаг 10. Остановка SparkContext\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf85d5ae-13e2-4d49-93d7-60d3e981952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178c5b07-91ac-48f6-93e8-022b583311be",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "---\n",
    "В рамках задания было вычислено косинусное сходство между фильмами MovieLens с использованием чистого **Spark RDD API**. Построены пары фильмов, оценённых одними и теми же пользователями, рассчитаны необходимые статистики и получено сходство для всех комбинаций. Для заданного фильма **сформирован список наиболее похожих фильмов** с добавлением их названий.\n",
    "\n",
    "Для повышения качества результатов применён фильтр по минимальному количеству общих пользователей. Это исключает пары, где высокое сходство возникает случайно из-за 1–2 совпавших оценок, и обеспечивает **статистическую надёжность** итогового топа.\n",
    "\n",
    "**Итоговый топ-10 похожих фильмов успешно получен, отсортирован и сохранён.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
