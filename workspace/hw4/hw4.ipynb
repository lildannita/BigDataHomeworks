{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81fd32c1-fddd-42be-a04b-977d9cf0e01e",
   "metadata": {},
   "source": [
    "# ДОМАШНЕЕ ЗАДАНИЕ № 4. Рекомендательные системы и Spark MLlib\n",
    "---\n",
    "**Дисциплина:** Методы обработки больших данных  \n",
    "**Студент:** Голдышев Д.М. (goldyshev02@mail.ru)  \n",
    "**Группа:** ИУ6-31М  \n",
    "\n",
    "## Задание 3. Факторизация матрицы\n",
    "---\n",
    "### Цель\n",
    "Построить и сравнить рекомендательные модели — **ALS** и **Item-based Collaborative Filtering** — с использованием **Spark MLlib** и **DataFrame API**.\n",
    "\n",
    "### Задачи\n",
    "1. Выбрать модель `ALS` по минимальному значению `RMSE` с помощью `k-fold` кросс-валидации (`k=4`).\n",
    "2. Параметры для перебора:\n",
    "    - Количество факторов: `[5, 10, 15]`;\n",
    "    - Регуляризация: `[0.001, 0.01, 0.1, 1, 10]`.\n",
    "3. Сравнить результаты рекомендаций посредством коллаборативной фильтрации и факторизации матрицы рейтингов.\n",
    "4. Выполнить анализ на двух датасетах: `ml-latest-small`, затем `ml-latest`.\n",
    "\n",
    "### Примечание\n",
    "В рамках задания, а именно в контексте необходимости *\"сравнить результаты рекомендаций посредством коллаборативной фильтрации и факторизации матрицы рейтингов\"*, было принято решение считать:\n",
    "- под «коллаборативной фильтрацией» — **Item-based CF**;\n",
    "- под «факторизацией матрицы» — **модель ALS**.\n",
    "\n",
    "Сравнение этих подходов позволяет сопоставить **базовый метод** (item-based CF, рекомендации по похожим фильмам) с **модельным методом** (ALS, латентные факторы)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2198b6c-0a48-44df-9161-80ccec249ad1",
   "metadata": {},
   "source": [
    "## Шаг 1. Импорт зависимостей и конфигурация\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ef6386d-7041-41aa-8bed-81560a77fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, \n",
    "    IntegerType, LongType, FloatType, DoubleType, StringType\n",
    ")\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# Только для RankingMetrics\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Путь к директории с данными MovieLens\n",
    "DATA_DIR_FULL = \"/app/data/ml-latest\"\n",
    "# Путь к директории с данными MovieLens (small)\n",
    "DATA_DIR_SMALL = \"/app/data/ml-latest-small\"\n",
    "\n",
    "# Гиперпараметры ALS\n",
    "RANKS = [5, 10, 15]                         # Количество латентных факторов\n",
    "REG_PARAMS = [0.001, 0.01, 0.1, 1.0, 10.0]  # Регуляризация L2\n",
    "MAX_ITER = 15                               # Максимум итераций ALS\n",
    "\n",
    "# Параметры кросс-валидации\n",
    "NUM_FOLDS = 4  # k-fold\n",
    "\n",
    "# Параметры Item-based CF\n",
    "MIN_COOC_COUNT = 5          # Минимальное число общих пользователей для расчёта сходства\n",
    "TOP_N_NEIGHBORS = 50        # Сколько соседей хранить для каждого фильма\n",
    "TOP_K_RECOMMENDATIONS = 10  # Топ-K рекомендаций для оценки Ranking-метрик\n",
    "\n",
    "# Порог релевантности\n",
    "RELEVANCE_THRESHOLD = 3.5  # Рейтинг >= 3.5 считается \"релевантным\" для Ranking-метрик\n",
    "\n",
    "# Для воспроизводимости:\n",
    "RANDOM_SEED = 23\n",
    "\n",
    "# Функция для печати \"заголовков\"\n",
    "def print_header(header: str):\n",
    "    print(\"=\" * 60)\n",
    "    print(header)\n",
    "    print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ab56c-9fbd-461a-940a-0d2e0000f93e",
   "metadata": {},
   "source": [
    "### Проверка существования данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92b48b72-f24f-4c9b-87c6-4648867f987b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файлы, необходимые для работы, найдены и читаются.\n"
     ]
    }
   ],
   "source": [
    "def check_file(path: str):\n",
    "    if not os.path.isfile(path):\n",
    "        raise FileNotFoundError(f\"{path}: файл не найден\")\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            f.read(1)  # пробное чтение\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"{path}: файл существует, но не читается: {e}\")\n",
    "\n",
    "def check_dataset_files(data_dir: str) -> None:\n",
    "    required_files = [\"ratings.csv\", \"movies.csv\", \"links.csv\", \"tags.csv\"]\n",
    "    for fname in required_files:\n",
    "        check_file(os.path.join(data_dir, fname))\n",
    "\n",
    "try:\n",
    "    check_dataset_files(DATA_DIR_SMALL)\n",
    "    # Т.к. всё равно пока что не можем работать с большим объемом данных\n",
    "    # check_dataset_files(DATA_DIR_FULL)\n",
    "    print(\"Файлы, необходимые для работы, найдены и читаются.\")\n",
    "except Exception as e:\n",
    "    print(\"Ошибка при проверке файлов:\")\n",
    "    print(e)\n",
    "    raise SystemExit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f1178-8c4a-4129-9717-4595612a6d39",
   "metadata": {},
   "source": [
    "## Шаг 2. Инициализация SparkSession\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8076e7-7fea-4dcd-be79-0506ac8a81b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/12/10 20:07:13 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/10 20:07:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/12/10 20:07:13 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://376646cee067:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>HW4_ALS</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x789739895d10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_spark_session(app_name: str) -> SparkSession:    \n",
    "    spark = (\n",
    "        SparkSession.builder\n",
    "        .appName(app_name)\n",
    "        # Включаем Adaptive Query Execution (для динамического перепланирования запроса во время выполнения)\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "        # Для автоматического сливания слишком маленьких партиций после shuffle\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "        # Broadcast threshold для небольших таблиц (которые целиком рассылаются на все executors)\n",
    "        .config(\"spark.sql.autoBroadcastJoinThreshold\", \"50MB\")\n",
    "        # Сериализация Kryo (пробуем более быструю и компактную сериализация объектов)\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\")\n",
    "        .getOrCreate()\n",
    "    )\n",
    "    # Количество партиций при shuffle и настройки памяти указаны на уровне Docker-контейнера\n",
    "    return spark\n",
    "\n",
    "# Создаём SparkSession\n",
    "spark = create_spark_session(\"HW4_ALS\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440deb0e-fb91-449a-881a-25a71482bbd3",
   "metadata": {},
   "source": [
    "## Шаг 3. Загрузка данных и определение схем\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f52479e-3928-4bfb-9593-1606cada42d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Данные из директории '/app/data/ml-latest-small' загружены за 0.66 сек\n",
      "+ Валидация данных пройдена успешно\n",
      "\n",
      "Размеры датасета ml-latest-small:\n",
      "  Рейтингов:         100,836\n",
      "  Пользователей:     610\n",
      "  Оцененных фильмов: 9,724\n",
      "  Всего фильмов:     9,742\n"
     ]
    }
   ],
   "source": [
    "# Явно задаем типы для надежности\n",
    "RATINGS_SCHEMA = StructType([\n",
    "    StructField(\"userId\", IntegerType(), nullable=False),\n",
    "    StructField(\"movieId\", IntegerType(), nullable=False),\n",
    "    StructField(\"rating\", FloatType(), nullable=False),\n",
    "    StructField(\"timestamp\", LongType(), nullable=True)  # Unix timestamp\n",
    "])\n",
    "MOVIES_SCHEMA = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), nullable=False),\n",
    "    StructField(\"title\", StringType(), nullable=True),\n",
    "    StructField(\"genres\", StringType(), nullable=True)  # pipe-separated\n",
    "])\n",
    "LINKS_SCHEMA = StructType([\n",
    "    StructField(\"movieId\", IntegerType(), nullable=False),\n",
    "    StructField(\"imdbId\", StringType(), nullable=True),\n",
    "    StructField(\"tmdbId\", IntegerType(), nullable=True)\n",
    "])\n",
    "TAGS_SCHEMA = StructType([\n",
    "    StructField(\"userId\", IntegerType(), nullable=False),\n",
    "    StructField(\"movieId\", IntegerType(), nullable=False),\n",
    "    StructField(\"tag\", StringType(), nullable=True),\n",
    "    StructField(\"timestamp\", LongType(), nullable=True)\n",
    "])\n",
    "\n",
    "def load_movielens_data(data_dir: str, spark: SparkSession) -> dict:\n",
    "    \"\"\"\n",
    "    Загружает все файлы датасета MovieLens.\n",
    "    Args:\n",
    "        data_dir: Путь к директории с данными\n",
    "        spark: SparkSession\n",
    "    Returns:\n",
    "        Словарь с DataFrame: ratings, movies, links, tags\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    ratings_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")  # Первая строка — заголовок\n",
    "        .schema(RATINGS_SCHEMA)    # Явная схема\n",
    "        .csv(f\"{data_dir}/ratings.csv\")\n",
    "    )\n",
    "    movies_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(MOVIES_SCHEMA)\n",
    "        .csv(f\"{data_dir}/movies.csv\")\n",
    "    )\n",
    "    links_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(LINKS_SCHEMA)\n",
    "        .csv(f\"{data_dir}/links.csv\")\n",
    "    )\n",
    "    tags_df = (\n",
    "        spark.read\n",
    "        .option(\"header\", \"true\")\n",
    "        .schema(TAGS_SCHEMA)\n",
    "        .csv(f\"{data_dir}/tags.csv\")\n",
    "    )\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"+ Данные из директории '{data_dir}' загружены за {elapsed:.2f} сек\")\n",
    "    return {\n",
    "        \"ratings\": ratings_df,\n",
    "        \"movies\": movies_df,\n",
    "        \"links\": links_df,\n",
    "        \"tags\": tags_df\n",
    "    }\n",
    "\n",
    "\n",
    "def validate_data(data: dict) -> None:\n",
    "    \"\"\"\n",
    "    Проверяет корректность загруженных данных.\n",
    "    Args:\n",
    "        data: Словарь с DataFrame\n",
    "    Raises:\n",
    "        AssertionError: Если данные некорректны\n",
    "    \"\"\"\n",
    "    ratings_df = data[\"ratings\"]\n",
    "    movies_df = data[\"movies\"]\n",
    "    \n",
    "    # Проверка: ratings не пустой\n",
    "    ratings_count = ratings_df.count()\n",
    "    assert ratings_count > 0, \"ratings.csv пустой!\"\n",
    "    \n",
    "    # Проверка: типы столбцов ratings\n",
    "    assert ratings_df.schema[\"userId\"].dataType == IntegerType(), \"userId должен быть IntegerType\"\n",
    "    assert ratings_df.schema[\"movieId\"].dataType == IntegerType(), \"movieId должен быть IntegerType\"\n",
    "    assert ratings_df.schema[\"rating\"].dataType == FloatType(), \"rating должен быть FloatType\"\n",
    "    \n",
    "    # Проверка: рейтинги в диапазоне [0.5, 5.0]\n",
    "    rating_stats = ratings_df.select(\n",
    "        F.min(\"rating\").alias(\"min_rating\"),\n",
    "        F.max(\"rating\").alias(\"max_rating\")\n",
    "    ).collect()[0]\n",
    "    assert rating_stats[\"min_rating\"] >= 0.5, f\"Минимальный рейтинг < 0.5: {rating_stats['min_rating']}\"\n",
    "    assert rating_stats[\"max_rating\"] <= 5.0, f\"Максимальный рейтинг > 5.0: {rating_stats['max_rating']}\"\n",
    "    \n",
    "    # Проверка: нет NULL в ключевых полях\n",
    "    null_ratings = ratings_df.filter(\n",
    "        F.col(\"userId\").isNull() | F.col(\"movieId\").isNull() | F.col(\"rating\").isNull()\n",
    "    ).count()\n",
    "    assert null_ratings == 0, f\"Найдено {null_ratings} записей с NULL в ratings\"\n",
    "    \n",
    "    # Проверка: movies не пустой\n",
    "    movies_count = movies_df.count()\n",
    "    assert movies_count > 0, \"movies.csv пустой!\"\n",
    "\n",
    "    print(\"+ Валидация данных пройдена успешно\")\n",
    "\n",
    "\n",
    "# Загружаем данные ml-latest-small\n",
    "data_small = load_movielens_data(DATA_DIR_SMALL, spark)\n",
    "validate_data(data_small)\n",
    "\n",
    "# Кэшируем для многократного использования\n",
    "ratings_small = data_small[\"ratings\"].cache()\n",
    "movies_small = data_small[\"movies\"].cache()\n",
    "\n",
    "# Статистика\n",
    "print(f\"\\nРазмеры датасета ml-latest-small:\")\n",
    "print(f\"  Рейтингов:         {ratings_small.count():,}\")\n",
    "print(f\"  Пользователей:     {ratings_small.select('userId').distinct().count():,}\")\n",
    "print(f\"  Оцененных фильмов: {ratings_small.select('movieId').distinct().count():,}\")\n",
    "print(f\"  Всего фильмов:     {movies_small.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf4f3a9-5c39-4a1f-8ea2-a79c504bd4f8",
   "metadata": {},
   "source": [
    "## Шаг 4. Подготовка данных и разбиение на train/test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b57314-9105-41c5-87d7-caf3e13ed7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Разбиение данных ml-latest-small:\n",
      "  Train: 80,467 рейтингов\n",
      "  Test:  20,369 рейтингов\n"
     ]
    }
   ],
   "source": [
    "def prepare_train_test_split(\n",
    "    ratings_df,\n",
    "    train_ratio: float = 0.8,\n",
    "    seed: int = RANDOM_SEED\n",
    ") -> Tuple:\n",
    "    \"\"\"\n",
    "    Разбивает данные на обучающую и тестовую выборки.    \n",
    "    Args:\n",
    "        ratings_df: DataFrame с рейтингами\n",
    "        train_ratio: Доля обучающей выборки\n",
    "        seed: Seed для воспроизводимости\n",
    "    Returns:\n",
    "        (train_df, test_df)\n",
    "    \"\"\"\n",
    "    train_df, test_df = ratings_df.randomSplit(\n",
    "        [train_ratio, 1 - train_ratio], \n",
    "        seed=seed\n",
    "    )\n",
    "    return train_df, test_df\n",
    "\n",
    "# Разбиваем данные: 80% train, 20% test\n",
    "train_small, test_small = prepare_train_test_split(ratings_small)\n",
    "\n",
    "# Кэшируем для многократного использования в CV\n",
    "train_small = train_small.cache()\n",
    "test_small = test_small.cache()\n",
    "\n",
    "print(f\"Разбиение данных ml-latest-small:\")\n",
    "print(f\"  Train: {train_small.count():,} рейтингов\")\n",
    "print(f\"  Test:  {test_small.count():,} рейтингов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853776c-386e-428a-94b9-604b0dd0d06d",
   "metadata": {},
   "source": [
    "## Шаг 5. ALS: Кросс-валидация с подбором гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a98cfa0-f7ef-4099-90ef-6e8b4aa36d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ОБУЧЕНИЕ ALS С КРОСС-ВАЛИДАЦИЕЙ\n",
      "============================================================\n",
      "Параметры поиска:\n",
      "  Ranks:      [5, 10, 15]\n",
      "  RegParams:  [0.001, 0.01, 0.1, 1.0, 10.0]\n",
      "  MaxIter:    15\n",
      "  NumFolds:   4\n",
      "  Комбинаций: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/10 20:07:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение завершено за 86.5 сек (1.4 мин)\n",
      "============================================================\n",
      "РЕЗУЛЬТАТЫ КРОСС-ВАЛИДАЦИИ\n",
      "============================================================\n",
      " rank  regParam  avg_rmse\n",
      "    5     0.100  0.913790\n",
      "   15     0.100  0.913995\n",
      "   10     0.100  0.917735\n",
      "    5     0.010  1.110020\n",
      "   10     0.010  1.229122\n",
      "   15     0.010  1.293958\n",
      "    5     1.000  1.324957\n",
      "   15     1.000  1.324958\n",
      "   10     1.000  1.324958\n",
      "    5     0.001  1.344002\n",
      "   10     0.001  1.465318\n",
      "   15     0.001  1.565245\n",
      "    5    10.000  3.664597\n",
      "   10    10.000  3.664597\n",
      "   15    10.000  3.664597\n",
      "============================================================\n",
      "ЛУЧШАЯ МОДЕЛЬ\n",
      "============================================================\n",
      "  Rank:     5\n",
      "  RegParam: 0.1\n",
      "  Avg RMSE: 0.913790\n"
     ]
    }
   ],
   "source": [
    "def train_als_with_cv(\n",
    "    train_df,\n",
    "    ranks: List[int] = RANKS,\n",
    "    reg_params: List[float] = REG_PARAMS,\n",
    "    max_iter: int = MAX_ITER,\n",
    "    num_folds: int = NUM_FOLDS,\n",
    "    seed: int = RANDOM_SEED\n",
    ") -> Tuple:\n",
    "    \"\"\"\n",
    "    Обучает ALS с кросс-валидацией и подбором гиперпараметров.\n",
    "    Args:\n",
    "        train_df: Обучающий DataFrame\n",
    "        ranks: Список значений количества факторов\n",
    "        reg_params: Список значений регуляризации\n",
    "        max_iter: Максимальное число итераций\n",
    "        num_folds: Число фолдов для CV\n",
    "        seed: Seed для воспроизводимости\n",
    "    Returns:\n",
    "        (best_model, cv_model, cv_results_df)\n",
    "    \"\"\"\n",
    "    print_header(\"ОБУЧЕНИЕ ALS С КРОСС-ВАЛИДАЦИЕЙ\")\n",
    "    print(f\"Параметры поиска:\")\n",
    "    print(f\"  Ranks:      {ranks}\")\n",
    "    print(f\"  RegParams:  {reg_params}\")\n",
    "    print(f\"  MaxIter:    {max_iter}\")\n",
    "    print(f\"  NumFolds:   {num_folds}\")\n",
    "    print(f\"  Комбинаций: {len(ranks) * len(reg_params)}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    # Создаём модель ALS с базовыми параметрами\n",
    "    als = ALS(\n",
    "        userCol=\"userId\",           # Столбец с ID пользователей\n",
    "        itemCol=\"movieId\",          # Столбец с ID фильмов\n",
    "        ratingCol=\"rating\",         # Столбец с рейтингами\n",
    "        maxIter=max_iter,           # Максимум итераций\n",
    "        coldStartStrategy=\"drop\",   # \"Холодные\" userId/movieId будут отброшены при вычислении метрик\n",
    "        implicitPrefs=False,        # У нас \"явные рейтинги\", не интерпретируем рейтинг как \"силу сигнала\"\n",
    "        nonnegative=False,          # Разрешаем отрицательные факторы\n",
    "        seed=seed                   # Фиксируем seed\n",
    "    )\n",
    "    \n",
    "    # Сетка гиперпараметров\n",
    "    param_grid = (\n",
    "        ParamGridBuilder()\n",
    "            .addGrid(als.rank, ranks)           # Количество латентных факторов\n",
    "            .addGrid(als.regParam, reg_params)  # L2 регуляризация\n",
    "            .build()\n",
    "    )\n",
    "    \n",
    "    # Настраиваем Evaluator для RMSE, определеляем, как мы измеряем \"качество\"\n",
    "    evaluator = RegressionEvaluator(\n",
    "        metricName=\"rmse\",          # Считаем корень из средней квадратичной ошибки\n",
    "        labelCol=\"rating\",          # Считаем за \"правду\"\n",
    "        predictionCol=\"prediction\"  # Считаем за \"предсказание\"\n",
    "    )\n",
    "    \n",
    "    # Настраиваем автоматический перебор моделей + кросс-валидация с k-fold\n",
    "    cv = CrossValidator(\n",
    "        estimator=als,\n",
    "        estimatorParamMaps=param_grid,\n",
    "        evaluator=evaluator,\n",
    "        numFolds=num_folds,\n",
    "        seed=seed,\n",
    "        parallelism=2  # Обучаем параллельно (т.к. ресурсов немного, то ставим )\n",
    "    )\n",
    "     \n",
    "    # Запуск кросс-валидации\n",
    "    cv_model = cv.fit(train_df)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Обучение завершено за {elapsed:.1f} сек ({elapsed/60:.1f} мин)\")\n",
    "    \n",
    "    # Извлекаем результаты CV\n",
    "    # avgMetrics — средний RMSE для каждой комбинации параметров\n",
    "    avg_metrics = cv_model.avgMetrics\n",
    "    \n",
    "    # Собираем результаты в DataFrame для анализа\n",
    "    cv_results = []\n",
    "    for i, params in enumerate(param_grid):\n",
    "        rank = params[als.rank]\n",
    "        reg_param = params[als.regParam]\n",
    "        rmse = avg_metrics[i]\n",
    "        cv_results.append({\n",
    "            \"rank\": rank,\n",
    "            \"regParam\": reg_param,\n",
    "            \"avg_rmse\": rmse\n",
    "        })\n",
    "\n",
    "    cv_results_df = pd.DataFrame(cv_results)\n",
    "    cv_results_df = cv_results_df.sort_values(\"avg_rmse\")\n",
    "    \n",
    "    # Лучшая модель\n",
    "    best_model = cv_model.bestModel\n",
    "    best_rank = best_model.rank\n",
    "    best_reg_param = best_model._java_obj.parent().getRegParam()\n",
    "    best_rmse = cv_results_df[\"avg_rmse\"].min()\n",
    "    \n",
    "    print_header(\"РЕЗУЛЬТАТЫ КРОСС-ВАЛИДАЦИИ\")\n",
    "    print(cv_results_df.to_string(index=False))\n",
    "\n",
    "    print_header(\"ЛУЧШАЯ МОДЕЛЬ\")\n",
    "    print(f\"  Rank:     {best_rank}\")\n",
    "    print(f\"  RegParam: {best_reg_param}\")\n",
    "    print(f\"  Avg RMSE: {best_rmse:.6f}\")\n",
    "\n",
    "    return best_model, cv_model, cv_results_df\n",
    "\n",
    "# Запускаем кросс-валидацию на небольшом датасете\n",
    "best_als_small, cv_model_small, cv_results_small = train_als_with_cv(train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc4dec5-c5dc-4979-a082-d18aa891a7e6",
   "metadata": {},
   "source": [
    "## Шаг 6. Оценка ALS на тестовой выборке\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6289492-50a8-41bf-8eb3-e056627648c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ОЦЕНКА ALS НА ТЕСТЕ\n",
      "============================================================\n",
      "Предсказания:\n",
      "  Строк в test:        20,369\n",
      "  Строк с prediction:  19,563\n",
      "  Потеряно (cold):     806 (3.96%)\n",
      "RMSE: 0.881034\n",
      "Время оценки: 0.33 сек\n"
     ]
    }
   ],
   "source": [
    "def evaluate_als_on_test(model, test_df) -> dict:\n",
    "    print_header(\"ОЦЕНКА ALS НА ТЕСТЕ\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Предсказания на тесте (coldStartStrategy=\"drop\" уже уберёт холодные пары)\n",
    "    predictions = model.transform(test_df)\n",
    "\n",
    "    # Считаем, сколько потеряли\n",
    "    n_test = test_df.count()\n",
    "    n_pred = predictions.count()\n",
    "    n_cold = n_test - n_pred\n",
    "    cold_pct = (n_cold / n_test * 100) if n_test > 0 else 0.0\n",
    "    \n",
    "    print(f\"Предсказания:\")\n",
    "    print(f\"  Строк в test:        {n_test:,}\")\n",
    "    print(f\"  Строк с prediction:  {n_pred:,}\")\n",
    "    print(f\"  Потеряно (cold):     {n_cold:,} ({cold_pct:.2f}%)\")\n",
    "    \n",
    "    evaluator = RegressionEvaluator(\n",
    "        metricName=\"rmse\",\n",
    "        labelCol=\"rating\",\n",
    "        predictionCol=\"prediction\"\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"RMSE: {rmse:.6f}\")\n",
    "    print(f\"Время оценки: {elapsed:.2f} сек\")\n",
    "    \n",
    "    return {\n",
    "        \"rmse\": rmse,\n",
    "        \"n_predictions\": n_pred,\n",
    "        \"n_cold_start\": n_cold\n",
    "    }\n",
    "\n",
    "# Оцениваем лучшую модель на тесте\n",
    "als_test_metrics_small = evaluate_als_on_test(\n",
    "    best_als_small, \n",
    "    test_small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed7f5e-8239-4427-89eb-313bcbcd38dc",
   "metadata": {},
   "source": [
    "### Ranking-метрики для ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce06be7e-a800-42ec-a497-26bc43b31f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANKING-МЕТРИКИ ALS @K=10 | mode = 'all'\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/pyspark/sql/context.py:158: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пользователей оценено: 598\n",
      "  Precision@10: 0.00083612\n",
      "  Recall@10:    0.00022951\n",
      "  MAP@10:       0.00027240\n",
      "  NDCG@10:      0.00083373\n",
      "Время: 3.01 сек\n",
      "============================================================\n",
      "RANKING-МЕТРИКИ ALS @K=10 | mode = 'warm'\n",
      "============================================================\n",
      "Пользователей оценено: 598\n",
      "  Precision@10: 0.00083612\n",
      "  Recall@10:    0.00023536\n",
      "  MAP@10:       0.00027240\n",
      "  NDCG@10:      0.00083373\n",
      "Время: 2.43 сек\n"
     ]
    }
   ],
   "source": [
    "# Для сокращения кода выделяем \"пустые\" метрики\n",
    "ZERO_METRICS = {\n",
    "    \"k\": TOP_K_RECOMMENDATIONS,\n",
    "    \"n_users\": 0,\n",
    "    \"precision_at_k\": 0.0,\n",
    "    \"recall_at_k\": 0.0,\n",
    "    \"map_at_k\": 0.0,\n",
    "    \"ndcg_at_k\": 0.0\n",
    "}\n",
    "\n",
    "def compute_ranking_metrics_als_both(\n",
    "    model,\n",
    "    train_df,\n",
    "    test_df,\n",
    "    k: int = TOP_K_RECOMMENDATIONS,\n",
    "    relevance_threshold: float = RELEVANCE_THRESHOLD\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Вычисляет ranking-метрики ALS в двух режимах:\n",
    "        1. \"all\" - насколько хорошо ALS способен угадывать все релевантные\n",
    "           фильмы в тесте, включая те, которых он никогда не видел?\n",
    "        2. \"warm\" - насколько хорошо ALS способен попасть в релевантные\n",
    "           фильмы среди тех, которые он хотя бы видел на обучении?\n",
    "    Args:\n",
    "        model:     Обученная ALS-модель\n",
    "        train_df:  Обучающая выборка\n",
    "        test_df:   Тестовая выборка\n",
    "        k:         Число рекомендаций K в метриках\n",
    "        relevance_threshold: Порог релевантности\n",
    "    Returns:\n",
    "        Словарь с метриками под каждый режим\n",
    "    \"\"\"\n",
    "    \n",
    "    def _compute_single_mode(mode: str) -> dict:\n",
    "        \"\"\"\n",
    "        Считает метрики для одного режима.\n",
    "        Args:\n",
    "            mode: Режим (\"all\", \"warm\")\n",
    "        Returns:\n",
    "            Словарь с метриками для выбранного режима\n",
    "        \"\"\"\n",
    "        assert mode in {\"all\", \"warm\"}\n",
    "        print_header(f\"RANKING-МЕТРИКИ ALS @K={k} | mode = '{mode}'\")\n",
    "    \n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Базовый ground truth - релевантные фильмы из test\n",
    "        ground_truth_base = test_df.filter(F.col(\"rating\") >= relevance_threshold)\n",
    "        # В режиме \"warm\" ограничиваемся фильмами из train\n",
    "        if mode == \"warm\":\n",
    "            # Все фильмы, которые модель \"видела\" при обучении\n",
    "            train_movies = train_df.select(\"movieId\").distinct()\n",
    "            # Оставляем только такие фильмы в ground truth\n",
    "            ground_truth_base = ground_truth_base.join(\n",
    "                train_movies, on=\"movieId\", how=\"inner\"\n",
    "            )\n",
    "        # Теперь строим для каждого пользователя список релевантных фильмов\n",
    "        ground_truth = (\n",
    "            ground_truth_base\n",
    "                .groupBy(\"userId\")\n",
    "                .agg(F.collect_set(\"movieId\").alias(\"relevant_movies\"))\n",
    "        )\n",
    "        \n",
    "        # Рекомендации ALS: топ-K фильмов для всех пользователей из теста\n",
    "        test_users = test_df.select(\"userId\").distinct()\n",
    "        recommendations = model.recommendForUserSubset(test_users, k)\n",
    "        # Оставляем userId и список рекомендованных movieId (без score)\n",
    "        recommendations_flat = (\n",
    "            recommendations\n",
    "                .select(\n",
    "                    \"userId\",\n",
    "                    F.col(\"recommendations.movieId\").alias(\"recommended_movies\")\n",
    "                )\n",
    "        )\n",
    "        \n",
    "        # Соединяем рекомендации и ground truth по userId\n",
    "        joined = recommendations_flat.join(ground_truth, on=\"userId\", how=\"inner\")\n",
    "        # Если ни одного пользователя не осталось, возвращаем нули\n",
    "        if joined.rdd.isEmpty():\n",
    "            print(\"! Нет пользователей для оценки в режиме\", mode)\n",
    "            return ZERO_METRICS\n",
    "        \n",
    "        # Преобразуем к формату RDD для RankingMetrics\n",
    "        prediction_and_labels_rdd = (\n",
    "            joined\n",
    "                .select(\"recommended_movies\", \"relevant_movies\")\n",
    "                .rdd\n",
    "                .map(lambda row: (row.recommended_movies, list(row.relevant_movies)))\n",
    "        )\n",
    "        \n",
    "        # Кэшируем, так как будем пробегаться по RDD несколько раз\n",
    "        prediction_and_labels_rdd.cache()\n",
    "        n_users = prediction_and_labels_rdd.count()\n",
    "        \n",
    "        if n_users == 0:\n",
    "            print(\"! Нет пользователей для оценки в режиме\", mode)\n",
    "            prediction_and_labels_rdd.unpersist()\n",
    "            return ZERO_METRICS\n",
    "        \n",
    "        # Считаем ranking-метрики через RankingMetrics\n",
    "        ranking_metrics = RankingMetrics(prediction_and_labels_rdd)\n",
    "        precision_at_k = ranking_metrics.precisionAt(k)\n",
    "        recall_at_k = ranking_metrics.recallAt(k)\n",
    "        map_at_k = ranking_metrics.meanAveragePrecisionAt(k)\n",
    "        ndcg_at_k = ranking_metrics.ndcgAt(k)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        print(f\"Пользователей оценено: {n_users}\")\n",
    "        print(f\"  Precision@{k}: {precision_at_k:.8f}\")\n",
    "        print(f\"  Recall@{k}:    {recall_at_k:.8f}\")\n",
    "        print(f\"  MAP@{k}:       {map_at_k:.8f}\")\n",
    "        print(f\"  NDCG@{k}:      {ndcg_at_k:.8f}\")\n",
    "        print(f\"Время: {elapsed:.2f} сек\")\n",
    "        \n",
    "        prediction_and_labels_rdd.unpersist()\n",
    "        \n",
    "        return {\n",
    "            \"k\": k,\n",
    "            \"n_users\": n_users,\n",
    "            \"precision_at_k\": precision_at_k,\n",
    "            \"recall_at_k\": recall_at_k,\n",
    "            \"map_at_k\": map_at_k,\n",
    "            \"ndcg_at_k\": ndcg_at_k\n",
    "        }\n",
    "    \n",
    "    # Считаем оба варианта и возвращаем в одном словаре\n",
    "    metrics_all  = _compute_single_mode(\"all\")\n",
    "    metrics_warm = _compute_single_mode(\"warm\")\n",
    "    \n",
    "    return {\n",
    "        \"all\": metrics_all,\n",
    "        \"warm\": metrics_warm\n",
    "    }\n",
    "\n",
    "als_ranking_small = compute_ranking_metrics_als_both(\n",
    "    best_als_small, train_small, test_small, k=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80cad7c-2d69-47f0-9d5f-0c1fd11ebcdd",
   "metadata": {},
   "source": [
    "### Интерпретация ranking-метрик ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55964ff5-583e-4258-ba30-8e58c8ccef23",
   "metadata": {},
   "source": [
    "Для оценки качества рекомендаций ALS были рассчитаны **ranking-метрики в двух режимах**:\n",
    "- `\"all\"` — учитываются все релевантные фильмы в тестовой выборке, включая фильмы, которые отсутствовали в обучающей выборке (cold items).\n",
    "- `\"warm\"` — учитываются только релевантные фильмы, присутствующие в обучающей выборке, то есть те фильмы, которые модель ALS способна рекомендовать в принципе.\n",
    "\n",
    "В обоих режимах значения `Precision@10`, `Recall@10`, `MAP@10` и `NDCG@10` оказались **крайне низкими** (менее 0.001), а различия между режимами оказались незначительными.\n",
    "\n",
    "Это объясняется следующими **факторами**:\n",
    "1. Датасет MovieLens является сильно разреженным: у большинства пользователей в тестовой выборке имеется лишь 1–2 релевантных фильма, что делает задачу попадания в них в топ-10 довольно сложной.\n",
    "2. Модель ALS оптимизируется по метрике RMSE, то есть по точности предсказания рейтингов, а не по качеству ранжирования рекомендаций.\n",
    "3. Даже для “тёплых” фильмов, присутствующих в обучающей выборке, модель часто присваивает более высокие predicted-оценки другим фильмам, которые пользователь в тесте не оценивал."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673f42c-9623-4d2a-b108-a33cfed646a5",
   "metadata": {},
   "source": [
    "### Примеры рекомендаций ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3426974e-15ee-49f4-980e-6c4b7fee3f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ПРИМЕРЫ РЕКОМЕНДАЦИЙ ALS\n",
      "============================================================\n",
      "\n",
      "Пользователь 1:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [7842  ] Dune (2000)                                                            (score: 6.349)\n",
      "  2. [3379  ] On the Beach (1959)                                                    (score: 6.189)\n",
      "  3. [6086  ] I, the Jury (1982)                                                     (score: 5.737)\n",
      "  4. [5915  ] Victory (a.k.a. Escape to Victory) (1981)                              (score: 5.710)\n",
      "  5. [7025  ] Midnight Clear, A (1992)                                               (score: 5.696)\n",
      "\n",
      "Пользователь 2:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [5075  ] Waydowntown (2000)                                                     (score: 5.715)\n",
      "  2. [32892 ] Ivan's Childhood (a.k.a. My Name is Ivan) (Ivanovo detstvo) (1962)     (score: 5.082)\n",
      "  3. [7842  ] Dune (2000)                                                            (score: 4.983)\n",
      "  4. [184245] De platte jungle (1978)                                                (score: 4.950)\n",
      "  5. [179135] Blue Planet II (2017)                                                  (score: 4.950)\n",
      "\n",
      "Пользователь 3:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [3837  ] Phantasm II (1988)                                                     (score: 5.335)\n",
      "  2. [5222  ] Kissing Jessica Stein (2001)                                           (score: 5.204)\n",
      "  3. [4438  ] Fist of Fury (Chinese Connection, The) (Jing wu men) (1972)            (score: 5.005)\n",
      "  4. [5746  ] Galaxy of Terror (Quest) (1981)                                        (score: 4.922)\n",
      "  5. [70946 ] Troll 2 (1990)                                                         (score: 4.893)\n"
     ]
    }
   ],
   "source": [
    "def show_sample_recommendations(\n",
    "    model,\n",
    "    movies_df,\n",
    "    n_users: int = 3,\n",
    "    n_recommendations: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Выводит примеры рекомендаций.\n",
    "    Args:\n",
    "        model: Обученная ALS-модель\n",
    "        movies_df: DataFrame со справочником фильмов\n",
    "        n_users: Количество пользователей, для которых выводим примеры\n",
    "        n_recommendations: Количество рекомендаций на пользователя\n",
    "    Returns:\n",
    "        List[int]: список userId, для которых были показаны примеры рекомендаций\n",
    "    \"\"\"\n",
    "    print_header(\"ПРИМЕРЫ РЕКОМЕНДАЦИЙ ALS\")\n",
    "\n",
    "    # Получаем рекомендации для всех пользователей\n",
    "    all_recs = model.recommendForAllUsers(n_recommendations)\n",
    "    # Берём первых n_users\n",
    "    sample_recs = all_recs.limit(n_users).collect()\n",
    "    # Список userId, для которых выводим примеры\n",
    "    sample_user_ids = [row[\"userId\"] for row in sample_recs]\n",
    "    # Локальный справочник movieId -> title\n",
    "    movies_local = {\n",
    "        row[\"movieId\"]: row[\"title\"]\n",
    "        for row in movies_df.select(\"movieId\", \"title\").collect()\n",
    "    }\n",
    "    \n",
    "    # Выводим рекомендации\n",
    "    for user_row in sample_recs:\n",
    "        user_id = user_row[\"userId\"]\n",
    "        recommendations = user_row[\"recommendations\"]\n",
    "        print(f\"\\nПользователь {user_id}:\")\n",
    "        print(\"-\" * 100)\n",
    "        for i, rec in enumerate(recommendations, 1):\n",
    "            movie_id = rec[\"movieId\"]\n",
    "            score = rec[\"rating\"]  # это предсказанный \"рейтинг\" ALS\n",
    "            title = movies_local.get(movie_id, \"Unknown\")\n",
    "            print(f\"  {i}. [{movie_id:<6}] {title[:70]:<70} (score: {score:.3f})\")\n",
    "        \n",
    "    return sample_user_ids\n",
    "\n",
    "# Выводим рекомендации и сохраняем список пользователей, для которых выводили рекомендации\n",
    "sample_user_ids = show_sample_recommendations(\n",
    "    best_als_small,\n",
    "    movies_small,\n",
    "    n_users=3,\n",
    "    n_recommendations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcd89c4-ff62-445d-accc-39c2be065447",
   "metadata": {},
   "source": [
    "### Объяснение полученных рекомендаций\n",
    "В модели ALS предсказанный рейтинг вычисляется как скалярное произведение векторов пользователя и фильма:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\mathbf{p}_u^\\top \\mathbf{q}_i\n",
    "$$\n",
    "\n",
    "При обучении модель **не ограничивается диапазоном** исходной шкалы рейтингов $[0.5; 5]$ и просто минимизирует ошибку (например, RMSE). Поэтому для некоторых пар \\((u, i)\\) значение скалярного произведения может оказаться больше 5 (или меньше 0.5). Это не ошибка, а следствие того, что модель оптимизирует точность предсказаний, а не строгое соблюдение границ шкалы: значения вроде $\\hat{r}_{u,i} > 5$ можно интерпретировать как “очень высокая ожидаемая симпатия пользователя к фильму”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae7c206-5139-4fca-9619-8773092e72e1",
   "metadata": {},
   "source": [
    "## Шаг 7. Item-based Collaborative Filtering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455f0c4b-b009-4021-9364-60eb7d9e2287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ПОСТРОЕНИЕ ITEM-BASED CF\n",
      "============================================================\n",
      "Параметры:\n",
      "  min_cooc_count:  5\n",
      "  top_n_neighbors: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/12/10 20:08:54 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/12/10 20:08:55 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "25/12/10 20:08:56 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Пар сходства:           227,428\n",
      "  Фильмов с соседями:     3,160\n",
      "  Время построения:       0.2 сек\n"
     ]
    }
   ],
   "source": [
    "def build_item_based_cf(\n",
    "    ratings_df,\n",
    "    min_cooc_count: int = MIN_COOC_COUNT,\n",
    "    top_n_neighbors: int = TOP_N_NEIGHBORS\n",
    "):\n",
    "    \"\"\"\n",
    "    Построение Item-based CF модели.\n",
    "    Args:\n",
    "        ratings_df: DataFrame с рейтингами\n",
    "        min_cooc_count: Минимум общих пользователей для сходства\n",
    "        top_n_neighbors: Сколько соседей хранить на фильм\n",
    "    Returns:\n",
    "        DataFrame с парами (movieId1, movieId2, similarity, cooc_count)\n",
    "    \"\"\"\n",
    "    print_header(\"ПОСТРОЕНИЕ ITEM-BASED CF\")\n",
    "    print(f\"Параметры:\")\n",
    "    print(f\"  min_cooc_count:  {min_cooc_count}\")\n",
    "    print(f\"  top_n_neighbors: {top_n_neighbors}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Нормализация рейтингов (центрирование по пользователю)\n",
    "    # Вычисляем средний рейтинг каждого пользователя через оконную функцию\n",
    "    user_window = Window.partitionBy(\"userId\")\n",
    "    ratings_centered = (\n",
    "        ratings_df\n",
    "        .withColumn(\n",
    "            \"avg_user_rating\",\n",
    "            F.avg(\"rating\").over(user_window)  # Средний рейтинг пользователя\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"rating_centered\",\n",
    "            F.col(\"rating\") - F.col(\"avg_user_rating\")  # Центрированный рейтинг\n",
    "        )\n",
    "        .select(\"userId\", \"movieId\", \"rating_centered\")\n",
    "    )\n",
    "    # Кэшируем, т.к. будем использовать дважды в self-join\n",
    "    ratings_centered = ratings_centered.cache()\n",
    "\n",
    "    # Для каждого пользователя соединяем все пары его оценённых фильмов    \n",
    "    # Переименовываем столбцы для join\n",
    "    ratings_left = ratings_centered.select(\n",
    "        F.col(\"userId\"),\n",
    "        F.col(\"movieId\").alias(\"movie1\"),\n",
    "        F.col(\"rating_centered\").alias(\"rating1\")\n",
    "    )\n",
    "    ratings_right = ratings_centered.select(\n",
    "        F.col(\"userId\"),\n",
    "        F.col(\"movieId\").alias(\"movie2\"),\n",
    "        F.col(\"rating_centered\").alias(\"rating2\")\n",
    "    )\n",
    "    # Self-join: находим все пары фильмов, оценённых одним пользователем\n",
    "    pairs = (\n",
    "        ratings_left\n",
    "            .join(ratings_right, on=\"userId\", how=\"inner\")\n",
    "            .filter(F.col(\"movie1\") < F.col(\"movie2\")) # Исключает дубликаты и пары (A, A)\n",
    "    )\n",
    "\n",
    "    # Агрегация для косинусного сходства\n",
    "    similarity_df = (\n",
    "        pairs\n",
    "            .groupBy(\"movie1\", \"movie2\")\n",
    "            .agg(\n",
    "                F.sum(F.col(\"rating1\") * F.col(\"rating2\")).alias(\"dot_product\"),  # Сумма произведений\n",
    "                F.sum(F.col(\"rating1\") ** 2).alias(\"norm1_sq\"),                   # Сумма квадратов первого рейтинга\n",
    "                F.sum(F.col(\"rating2\") ** 2).alias(\"norm2_sq\"),                   # Сумма квадратов второго рейтинга\n",
    "                F.count(\"*\").alias(\"cooc_count\")                                  # Число общих пользователей\n",
    "            )\n",
    "            # Фильтруем по минимальному числу общих пользователей\n",
    "            .filter(F.col(\"cooc_count\") >= min_cooc_count)\n",
    "            # Вычисляем косинусное сходство\n",
    "            .withColumn(\n",
    "                \"similarity\",\n",
    "                F.col(\"dot_product\") / (\n",
    "                    F.sqrt(F.col(\"norm1_sq\")) * F.sqrt(F.col(\"norm2_sq\"))\n",
    "                )\n",
    "            )\n",
    "            # Обрабатываем деление на ноль (если все рейтинги одинаковые)\n",
    "            .withColumn(\n",
    "                \"similarity\",\n",
    "                F.when(F.col(\"similarity\").isNull(), 0.0)\n",
    "                 .otherwise(F.col(\"similarity\"))\n",
    "            )\n",
    "            .select(\"movie1\", \"movie2\", \"similarity\", \"cooc_count\")\n",
    "    )\n",
    "\n",
    "    # Отбор top-N соседей для каждого фильма\n",
    "    # Для movie1: ранжируем movie2 по similarity\n",
    "    window_movie1 = Window.partitionBy(\"movie1\").orderBy(F.desc(\"similarity\"))    \n",
    "    neighbors_for_movie1 = (\n",
    "        similarity_df\n",
    "            .withColumn(\"rank\", F.row_number().over(window_movie1))\n",
    "            .filter(F.col(\"rank\") <= top_n_neighbors)\n",
    "            .select(\n",
    "                F.col(\"movie1\").alias(\"movieId\"),\n",
    "                F.col(\"movie2\").alias(\"neighborId\"),\n",
    "                \"similarity\",\n",
    "                \"cooc_count\"\n",
    "            )\n",
    "    )\n",
    "    # Для movie2: ранжируем movie1 по similarity\n",
    "    window_movie2 = Window.partitionBy(\"movie2\").orderBy(F.desc(\"similarity\"))\n",
    "    neighbors_for_movie2 = (\n",
    "        similarity_df\n",
    "            .withColumn(\"rank\", F.row_number().over(window_movie2))\n",
    "            .filter(F.col(\"rank\") <= top_n_neighbors)\n",
    "            .select(\n",
    "                F.col(\"movie2\").alias(\"movieId\"),\n",
    "                F.col(\"movie1\").alias(\"neighborId\"),\n",
    "                \"similarity\",\n",
    "                \"cooc_count\"\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # Объединяем и убираем дубликаты\n",
    "    item_similarity = (\n",
    "        neighbors_for_movie1\n",
    "            .union(neighbors_for_movie2)\n",
    "            .dropDuplicates([\"movieId\", \"neighborId\"])\n",
    "    )\n",
    "    # Кэшируем результат\n",
    "    item_similarity = item_similarity.cache()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    n_similarities = item_similarity.count()\n",
    "    n_movies_with_neighbors = item_similarity.select(\"movieId\").distinct().count()\n",
    "    print(f\"\\n  Пар сходства:           {n_similarities:,}\")\n",
    "    print(f\"  Фильмов с соседями:     {n_movies_with_neighbors:,}\")\n",
    "    print(f\"  Время построения:       {elapsed:.1f} сек\")\n",
    "    \n",
    "    # Освобождаем промежуточный кэш\n",
    "    ratings_centered.unpersist()\n",
    "    \n",
    "    return item_similarity\n",
    "\n",
    "\n",
    "# Строим Item-based CF на обучающих данных\n",
    "item_similarity_small = build_item_based_cf(train_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff1e609-a374-466d-a24a-ce18396af5db",
   "metadata": {},
   "source": [
    "### Генерация рекомендаций Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5db6bd1b-1a48-4ca5-ab26-8ce0aa0db00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ГЕНЕРАЦИЯ РЕКОМЕНДАЦИЙ ITEM-BASED CF (топ-10)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сгенерировано рекомендаций: 6,100\n",
      "Пользователей с рекомендациями: 610\n",
      "Время: 3.8 сек\n"
     ]
    }
   ],
   "source": [
    "def generate_itembased_recommendations(\n",
    "    item_similarity,\n",
    "    user_ratings,\n",
    "    test_users,\n",
    "    k: int = TOP_K_RECOMMENDATIONS\n",
    "):\n",
    "    \"\"\"\n",
    "    Генерирует топ-K рекомендаций для пользователей.\n",
    "    Args:\n",
    "        item_similarity: DataFrame с парами (movieId, neighborId, similarity)\n",
    "        user_ratings: DataFrame с центрированными рейтингами пользователей\n",
    "        test_users: DataFrame с userId для которых нужны рекомендации\n",
    "        k: Количество рекомендаций\n",
    "    Returns:\n",
    "        DataFrame с (userId, movieId, score)\n",
    "    \"\"\"\n",
    "    print_header(f\"ГЕНЕРАЦИЯ РЕКОМЕНДАЦИЙ ITEM-BASED CF (топ-{k})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Центрируем рейтинги пользователей\n",
    "    user_window = Window.partitionBy(\"userId\")\n",
    "    user_ratings_centered = (\n",
    "        user_ratings\n",
    "            .withColumn(\"avg_user_rating\", F.avg(\"rating\").over(user_window))\n",
    "            .withColumn(\"rating_centered\", F.col(\"rating\") - F.col(\"avg_user_rating\"))\n",
    "            .select(\"userId\", \"movieId\", \"rating_centered\", \"avg_user_rating\")\n",
    "    )\n",
    "    \n",
    "    # Фильтруем только пользователей из test_users\n",
    "    user_ratings_filtered = user_ratings_centered.join(test_users, on=\"userId\", how=\"inner\")\n",
    "    \n",
    "    # Соединяем рейтинги пользователя с матрицей сходства\n",
    "    # Для каждого оценённого фильма находим его соседей\n",
    "    joined = (\n",
    "        user_ratings_filtered\n",
    "            .join(\n",
    "                item_similarity,\n",
    "                user_ratings_filtered[\"movieId\"] == item_similarity[\"neighborId\"],\n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .select(\n",
    "                user_ratings_filtered[\"userId\"],\n",
    "                item_similarity[\"movieId\"].alias(\"candidate_movieId\"),\n",
    "                user_ratings_filtered[\"rating_centered\"],\n",
    "                user_ratings_filtered[\"avg_user_rating\"],\n",
    "                item_similarity[\"similarity\"]\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # Исключаем фильмы, которые пользователь уже смотрел\n",
    "    already_rated = user_ratings_filtered.select(\"userId\", \"movieId\")\n",
    "    candidates = (\n",
    "        joined\n",
    "            .join(\n",
    "                already_rated,\n",
    "                (joined[\"userId\"] == already_rated[\"userId\"]) & \n",
    "                (joined[\"candidate_movieId\"] == already_rated[\"movieId\"]),\n",
    "                how=\"left_anti\"  # Исключаем совпадения\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # Агрегируем: вычисляем взвешенный score\n",
    "    scores = (\n",
    "        candidates\n",
    "            .groupBy(\"userId\", \"candidate_movieId\")\n",
    "            .agg(\n",
    "                F.sum(F.col(\"similarity\") * F.col(\"rating_centered\")).alias(\"weighted_sum\"),\n",
    "                F.sum(F.abs(F.col(\"similarity\"))).alias(\"sim_sum\"),\n",
    "                F.first(\"avg_user_rating\").alias(\"avg_user_rating\")\n",
    "            )\n",
    "            .withColumn(\n",
    "                \"predicted_rating\",\n",
    "                F.col(\"avg_user_rating\") + F.col(\"weighted_sum\") / F.col(\"sim_sum\")\n",
    "            )\n",
    "            .filter(F.col(\"sim_sum\") > 0)  # Избегаем деления на ноль\n",
    "    )\n",
    "    \n",
    "    # Отбираем топ-K для каждого пользователя\n",
    "    window_user = Window.partitionBy(\"userId\").orderBy(F.desc(\"predicted_rating\"))\n",
    "    recommendations = (\n",
    "        scores\n",
    "            .withColumn(\"rank\", F.row_number().over(window_user))\n",
    "            .filter(F.col(\"rank\") <= k)\n",
    "            .select(\n",
    "                \"userId\",\n",
    "                F.col(\"candidate_movieId\").alias(\"movieId\"),\n",
    "                \"predicted_rating\",\n",
    "                \"rank\"\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    recommendations = recommendations.cache()\n",
    "    n_recs = recommendations.count()\n",
    "    n_users_with_recs = recommendations.select(\"userId\").distinct().count()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Сгенерировано рекомендаций: {n_recs:,}\")\n",
    "    print(f\"Пользователей с рекомендациями: {n_users_with_recs:,}\")\n",
    "    print(f\"Время: {elapsed:.1f} сек\")\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# Генерируем рекомендации Item-based CF для тестовых пользователей\n",
    "test_users_small = test_small.select(\"userId\").distinct()\n",
    "itembased_recs_small = generate_itembased_recommendations(\n",
    "    item_similarity_small,\n",
    "    train_small,\n",
    "    test_users_small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91573c-9abe-431f-ba49-25436577d580",
   "metadata": {},
   "source": [
    "### RMSE для Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7de45e5b-03b5-4fdc-97bd-f60cdf8b9eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ОЦЕНКА RMSE ITEM-BASED CF\n",
      "============================================================\n",
      "Предсказаний: 16,793\n",
      "RMSE: 0.899836\n",
      "Время: 1.4 сек\n"
     ]
    }
   ],
   "source": [
    "def evaluate_itembased_rmse(\n",
    "    item_similarity,\n",
    "    train_df,\n",
    "    test_df\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Оценивает RMSE предсказаний Item-based CF на тестовых данных.\n",
    "    Args:\n",
    "        item_similarity: DataFrame с матрицей сходства\n",
    "        train_df: Обучающий DataFrame\n",
    "        test_df: Тестовый DataFrame\n",
    "    Returns:\n",
    "        RMSE\n",
    "    \"\"\"\n",
    "    print_header(\"ОЦЕНКА RMSE ITEM-BASED CF\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Центрируем train рейтинги\n",
    "    user_window = Window.partitionBy(\"userId\")\n",
    "    train_centered = (\n",
    "        train_df\n",
    "        .withColumn(\"avg_user_rating\", F.avg(\"rating\").over(user_window))\n",
    "        .withColumn(\"rating_centered\", F.col(\"rating\") - F.col(\"avg_user_rating\"))\n",
    "    )\n",
    "\n",
    "    # Для каждой пары (user, movie) из теста предсказываем рейтинг\n",
    "    # Соединяем тестовые записи с train через матрицу сходства\n",
    "    predictions = (\n",
    "        test_df\n",
    "            .alias(\"test\")\n",
    "            .join(\n",
    "                item_similarity.alias(\"sim\"),\n",
    "                F.col(\"test.movieId\") == F.col(\"sim.movieId\"),\n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .join(\n",
    "                train_centered.alias(\"train\"),\n",
    "                (F.col(\"test.userId\") == F.col(\"train.userId\")) & \n",
    "                (F.col(\"sim.neighborId\") == F.col(\"train.movieId\")),\n",
    "                how=\"inner\"\n",
    "            )\n",
    "            .groupBy(\n",
    "                F.col(\"test.userId\").alias(\"userId\"),\n",
    "                F.col(\"test.movieId\").alias(\"movieId\"),\n",
    "                F.col(\"test.rating\").alias(\"actual_rating\")\n",
    "            )\n",
    "            .agg(\n",
    "                F.sum(F.col(\"sim.similarity\") * F.col(\"train.rating_centered\")).alias(\"weighted_sum\"),\n",
    "                F.sum(F.abs(F.col(\"sim.similarity\"))).alias(\"sim_sum\"),\n",
    "                F.first(\"train.avg_user_rating\").alias(\"avg_user_rating\")\n",
    "            )\n",
    "            .filter(F.col(\"sim_sum\") > 0)\n",
    "            .withColumn(\n",
    "                \"prediction\",\n",
    "                F.col(\"avg_user_rating\") + F.col(\"weighted_sum\") / F.col(\"sim_sum\")\n",
    "            )\n",
    "    )\n",
    "    \n",
    "    # Вычисляем RMSE\n",
    "    rmse_df = (\n",
    "        predictions\n",
    "            .withColumn(\n",
    "                \"squared_error\",\n",
    "                (F.col(\"actual_rating\") - F.col(\"prediction\")) ** 2\n",
    "            )\n",
    "            .agg(F.sqrt(F.avg(\"squared_error\")).alias(\"rmse\"))\n",
    "    )\n",
    "    \n",
    "    rmse = rmse_df.collect()[0][\"rmse\"]\n",
    "    n_predictions = predictions.count()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Предсказаний: {n_predictions:,}\")\n",
    "    print(f\"RMSE: {rmse:.6f}\")\n",
    "    print(f\"Время: {elapsed:.1f} сек\")\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "itembased_rmse_small = evaluate_itembased_rmse(\n",
    "    item_similarity_small,\n",
    "    train_small,\n",
    "    test_small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a642bac-47dd-4957-9e30-cbd6a19f07d9",
   "metadata": {},
   "source": [
    "### Ranking-метрики для Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f40d6ae-6387-46ea-b906-fd61a3bcc987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RANKING-МЕТРИКИ ITEM-BASED CF @ K=10\n",
      "============================================================\n",
      "Пользователей оценено: 598\n",
      "Metrics@10:\n",
      "  Precision@10: 0.003679\n",
      "  Recall@10:    0.002541\n",
      "  MAP@10:       0.001331\n",
      "  NDCG@10:      0.004215\n",
      "Время: 0.87 сек\n"
     ]
    }
   ],
   "source": [
    "def compute_ranking_metrics_itembased(\n",
    "    recommendations_df,\n",
    "    test_df,\n",
    "    k: int = TOP_K_RECOMMENDATIONS,\n",
    "    relevance_threshold: float = RELEVANCE_THRESHOLD\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Вычисляет Ranking-метрики для Item-based CF.\n",
    "    Args:\n",
    "        recommendations_df: DataFrame с рекомендациями\n",
    "        test_df: Тестовый DataFrame\n",
    "        k: Количество рекомендаций для оценки\n",
    "        relevance_threshold: Порог релевантности\n",
    "    Returns:\n",
    "        Словарь с метриками\n",
    "    \"\"\"\n",
    "    print_header(f\"RANKING-МЕТРИКИ ITEM-BASED CF @ K={k}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Ground truth: релевантные фильмы для каждого пользователя\n",
    "    ground_truth = (\n",
    "        test_df\n",
    "            .filter(F.col(\"rating\") >= relevance_threshold)\n",
    "            .groupBy(\"userId\")\n",
    "            .agg(F.collect_set(\"movieId\").alias(\"relevant_movies\"))\n",
    "    )\n",
    "    \n",
    "    # Рекомендации в формате списка для каждого пользователя\n",
    "    recommendations_agg = (\n",
    "        recommendations_df\n",
    "            .filter(F.col(\"rank\") <= k)\n",
    "            .groupBy(\"userId\")\n",
    "            .agg(\n",
    "                F.collect_list(\n",
    "                    F.struct(F.col(\"rank\"), F.col(\"movieId\"))\n",
    "                ).alias(\"recs_struct\")\n",
    "            )\n",
    "            # Сортируем по rank и извлекаем movieId\n",
    "            .withColumn(\n",
    "                \"recommended_movies\",\n",
    "                F.transform(\n",
    "                    F.array_sort(\"recs_struct\"),\n",
    "                    lambda x: x.getField(\"movieId\")\n",
    "                )\n",
    "            )\n",
    "            .select(\"userId\", \"recommended_movies\")\n",
    "    )\n",
    "    \n",
    "    # Соединяем\n",
    "    joined = recommendations_agg.join(ground_truth, on=\"userId\", how=\"inner\")\n",
    "    # Конвертируем в RDD для RankingMetrics\n",
    "    prediction_and_labels_rdd = (\n",
    "        joined\n",
    "        .select(\"recommended_movies\", \"relevant_movies\")\n",
    "        .rdd\n",
    "        .map(lambda row: (list(row.recommended_movies), list(row.relevant_movies)))\n",
    "    )\n",
    "    \n",
    "    prediction_and_labels_rdd.cache()\n",
    "    n_users_evaluated = prediction_and_labels_rdd.count()\n",
    "    \n",
    "    if n_users_evaluated == 0:\n",
    "        print(\"! Нет пользователей с релевантными фильмами!\")\n",
    "        return {\"precision_at_k\": 0, \"recall_at_k\": 0, \"map_at_k\": 0, \"ndcg_at_k\": 0}\n",
    "    \n",
    "    # RankingMetrics\n",
    "    ranking_metrics = RankingMetrics(prediction_and_labels_rdd)\n",
    "    precision_at_k = ranking_metrics.precisionAt(k)\n",
    "    recall_at_k = ranking_metrics.recallAt(k)\n",
    "    map_at_k = ranking_metrics.meanAveragePrecisionAt(k)\n",
    "    ndcg_at_k = ranking_metrics.ndcgAt(k)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(f\"Пользователей оценено: {n_users_evaluated:,}\")\n",
    "    print(f\"Metrics@{k}:\")\n",
    "    print(f\"  Precision@{k}: {precision_at_k:.6f}\")\n",
    "    print(f\"  Recall@{k}:    {recall_at_k:.6f}\")\n",
    "    print(f\"  MAP@{k}:       {map_at_k:.6f}\")\n",
    "    print(f\"  NDCG@{k}:      {ndcg_at_k:.6f}\")\n",
    "    print(f\"Время: {elapsed:.2f} сек\")\n",
    "    \n",
    "    prediction_and_labels_rdd.unpersist()\n",
    "    \n",
    "    return {\n",
    "        \"precision_at_k\": precision_at_k,\n",
    "        \"recall_at_k\": recall_at_k,\n",
    "        \"map_at_k\": map_at_k,\n",
    "        \"ndcg_at_k\": ndcg_at_k,\n",
    "        \"k\": k,\n",
    "        \"n_users\": n_users_evaluated\n",
    "    }\n",
    "\n",
    "\n",
    "# Вычисляем Ranking-метрики для Item-based CF\n",
    "itembased_ranking_small = compute_ranking_metrics_itembased(\n",
    "    itembased_recs_small,\n",
    "    test_small\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2490e1e3-0a5d-4a22-b334-3841e0d9fe21",
   "metadata": {},
   "source": [
    "### Примеры рекомендаций Item-based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58e00499-999a-4a24-a9c7-9bff1dc95a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ПРИМЕРЫ РЕКОМЕНДАЦИЙ ITEM-BASED CF\n",
      "============================================================\n",
      "\n",
      "Пользователь 1:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [2548  ] Rage: Carrie 2, The (1999)                                             (predicted: 6.462)\n",
      "  2. [4649  ] Wet Hot American Summer (2001)                                         (predicted: 5.774)\n",
      "  3. [51939 ] TMNT (Teenage Mutant Ninja Turtles) (2007)                             (predicted: 5.774)\n",
      "  4. [8966  ] Kinsey (2004)                                                          (predicted: 5.774)\n",
      "  5. [255   ] Jerky Boys, The (1995)                                                 (predicted: 5.774)\n",
      "\n",
      "Пользователь 2:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [707   ] Mulholland Falls (1996)                                                (predicted: 5.160)\n",
      "  2. [1537  ] Shall We Dance? (Shall We Dansu?) (1996)                               (predicted: 5.160)\n",
      "  3. [188   ] Prophecy, The (1995)                                                   (predicted: 5.160)\n",
      "  4. [2136  ] Nutty Professor, The (1963)                                            (predicted: 5.160)\n",
      "  5. [94780 ] Snow White and the Huntsman (2012)                                     (predicted: 5.160)\n",
      "\n",
      "Пользователь 3:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  1. [880   ] Island of Dr. Moreau, The (1996)                                       (predicted: 5.000)\n",
      "  2. [1230  ] Annie Hall (1977)                                                      (predicted: 5.000)\n",
      "  3. [4378  ] Sexy Beast (2000)                                                      (predicted: 5.000)\n",
      "  4. [110102] Captain America: The Winter Soldier (2014)                             (predicted: 5.000)\n",
      "  5. [2528  ] Logan's Run (1976)                                                     (predicted: 5.000)\n"
     ]
    }
   ],
   "source": [
    "def show_sample_recommendations_itembased(\n",
    "    recommendations_df,\n",
    "    movies_df,\n",
    "    user_ids,\n",
    "    n_recommendations: int = 5\n",
    "):\n",
    "    \"\"\"\n",
    "    Выводит примеры рекомендаций Item-based CF для заданных пользователей.\n",
    "    Args:\n",
    "        recommendations_df: DataFrame с рекомендациями Item-based CF\n",
    "        movies_df: DataFrame со справочником фильмов\n",
    "        user_ids: Список userId, для которых нужно показать пример.\n",
    "        n_recommendations: Количество рекомендаций на пользователя\n",
    "    \"\"\"\n",
    "    print_header(\"ПРИМЕРЫ РЕКОМЕНДАЦИЙ ITEM-BASED CF\")\n",
    "\n",
    "    # Локальный справочник movieId -> title\n",
    "    movies_local = {\n",
    "        row[\"movieId\"]: row[\"title\"]\n",
    "        for row in movies_df.select(\"movieId\", \"title\").collect()\n",
    "    }\n",
    "\n",
    "    # Выводим рекомендации\n",
    "    for user_id in user_ids:\n",
    "        print(f\"\\nПользователь {user_id}:\")\n",
    "        print(\"-\" * 100)\n",
    "        user_recs = (\n",
    "            recommendations_df\n",
    "            .filter(F.col(\"userId\") == user_id)\n",
    "            .orderBy(\"rank\")\n",
    "            .limit(n_recommendations)\n",
    "            .collect()\n",
    "        )\n",
    "        if not user_recs:\n",
    "            print(\"    (нет сгенерированных рекомендаций для этого пользователя)\")\n",
    "            continue\n",
    "        for rec in user_recs:\n",
    "            movie_id = rec[\"movieId\"]\n",
    "            score = rec[\"predicted_rating\"]\n",
    "            rank = rec[\"rank\"]\n",
    "            title = movies_local.get(movie_id, \"Unknown\")\n",
    "            print(f\"  {rank}. [{movie_id:<6}] {title[:70]:<70} (predicted: {score:.3f})\")\n",
    "\n",
    "show_sample_recommendations_itembased(\n",
    "    itembased_recs_small,\n",
    "    movies_small,\n",
    "    user_ids=sample_user_ids,\n",
    "    n_recommendations=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb8d61-4922-4297-b6a0-3a47ce50c420",
   "metadata": {},
   "source": [
    "### Объяснение полученных рекомендаций\n",
    "В Item-based CF предсказание обычно строится как отклонение от среднего рейтинга пользователя с учётом похожих фильмов:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\bar{r}_u + \\frac{ \\sum\\limits_{j \\in N(i)} s_{i,j} \\cdot (r_{u,j} - \\bar{r}_u) }{ \\sum\\limits_{j \\in N(i)} |s_{i,j}|}\n",
    "$$\n",
    "\n",
    "где  \n",
    "$\\bar{r}_u$ — средний рейтинг пользователя $u$,  \n",
    "$N(i)$ — множество фильмов, похожих на фильм $i$,  \n",
    "$s_{i,j}$ — мера сходства между фильмами $i$ и $j$,  \n",
    "$r_{u,j}$ — рейтинг пользователя $u$ для фильма $j$.\n",
    "\n",
    "Если пользователь ставил многим похожим фильмам оценки заметно выше своего среднего, числитель может получиться достаточно большим, а итоговое $\\hat{r}_{u,i}$ — больше 5. Поскольку формула не ограничивается рамками шкалы $[0.5; 5]$, такие значения являются допустимым результатом и отражают то, что модель ожидает от пользователя “сверхвысокую” оценку этого фильма."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba018d4-acbb-4822-9bf2-8cee9fc3308d",
   "metadata": {},
   "source": [
    "## Шаг 9. Сравнение ALS vs Item-based CF\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c856f51-6b68-4730-b4b6-ee5de1793b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "СРАВНЕНИЕ МОДЕЛЕЙ\n",
      "============================================================\n",
      "     Metrics      ALS  Item-based CF    Comparison\n",
      "        RMSE 0.881034       0.899836           ALS\n",
      "Precision@10 0.000836       0.003679 Item-based CF\n",
      "   Recall@10 0.000230       0.002541 Item-based CF\n",
      "      MAP@10 0.000272       0.001331 Item-based CF\n",
      "     NDCG@10 0.000834       0.004215 Item-based CF\n"
     ]
    }
   ],
   "source": [
    "def compare_models(\n",
    "    als_rmse: float,\n",
    "    als_ranking: dict,\n",
    "    itembased_rmse: float,\n",
    "    itembased_ranking: dict,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Сравнивает метрики ALS и Item-based CF.\n",
    "    Args:\n",
    "        als_rmse: RMSE модели ALS\n",
    "        als_ranking: Ranking-метрики ALS\n",
    "        itembased_rmse: RMSE Item-based CF\n",
    "        itembased_ranking: Ranking-метрики Item-based CF\n",
    "    Returns:\n",
    "        DataFrame со сравнительной таблицей\n",
    "    \"\"\"\n",
    "    k = als_ranking[\"k\"]\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Metrics\": [\n",
    "            \"RMSE\",\n",
    "            f\"Precision@{k}\",\n",
    "            f\"Recall@{k}\",\n",
    "            f\"MAP@{k}\",\n",
    "            f\"NDCG@{k}\"\n",
    "        ],\n",
    "        \"ALS\": [\n",
    "            als_rmse,\n",
    "            als_ranking[\"precision_at_k\"],\n",
    "            als_ranking[\"recall_at_k\"],\n",
    "            als_ranking[\"map_at_k\"],\n",
    "            als_ranking[\"ndcg_at_k\"]\n",
    "        ],\n",
    "        \"Item-based CF\": [\n",
    "            itembased_rmse,\n",
    "            itembased_ranking[\"precision_at_k\"],\n",
    "            itembased_ranking[\"recall_at_k\"],\n",
    "            itembased_ranking[\"map_at_k\"],\n",
    "            itembased_ranking[\"ndcg_at_k\"]\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Добавляем столбец \"Лучше\"\n",
    "    comparison[\"Comparison\"] = comparison.apply(\n",
    "        lambda row: (\n",
    "            \"Equal\"  # случай равенства\n",
    "            if row[\"ALS\"] == row[\"Item-based CF\"]\n",
    "            else (\n",
    "                \"ALS\"\n",
    "                if (\n",
    "                    (row[\"Metrics\"] == \"RMSE\" and row[\"ALS\"] < row[\"Item-based CF\"]) or\n",
    "                    (row[\"Metrics\"] != \"RMSE\" and row[\"ALS\"] > row[\"Item-based CF\"])\n",
    "                )\n",
    "                else \"Item-based CF\"\n",
    "            )\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Выводим результат сравнения\n",
    "    print_header(\"СРАВНЕНИЕ МОДЕЛЕЙ\")\n",
    "    print(comparison.to_string(index=False))\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "\n",
    "# Сравниваем модели на small-датасете\n",
    "comparison_small = compare_models(\n",
    "    als_test_metrics_small[\"rmse\"],\n",
    "    als_ranking_small[\"all\"], # Используем режим \"all\", \"warm\" использовался только для анализа\n",
    "    itembased_rmse_small,\n",
    "    itembased_ranking_small,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac0b939-0102-453e-a9a5-82a7cca8e04c",
   "metadata": {},
   "source": [
    "### Интерпретация результатов сравнения\n",
    "**По RMSE модель ALS показала лучшее качество**, что означает более точное приближение численных рейтингов.\n",
    "\n",
    "Однако **по ranking-метрикам значительно лучше оказался Item-based CF**. Это связано с тем, что:\n",
    "- ALS оптимизируется по RMSE и стремится точно предсказывать рейтинги во всём диапазоне, но не фокусируется на качестве топ-N рекомендаций;\n",
    "- Item-based CF, напротив, строит рекомендации исходя из похожести на уже понравившиеся фильмы и фактически оптимизирован под задачу \"найти ещё несколько релевантных фильмов для пользователя\", пусть и ценой менее точных численных предсказаний.\n",
    "\n",
    "Таким образом, **ALS лучше калиброван как регрессионная модель, тогда как Item-based CF даёт более удачные top-K списки рекомендаций**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc03f1-da9c-412a-929a-894c1b98b631",
   "metadata": {},
   "source": [
    "### Освобождаем ресурсы для small-датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9940883b-cc87-484e-9d68-7ef8d572aad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[movieId: int, neighborId: int, similarity: double, cooc_count: bigint]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_small.unpersist()\n",
    "movies_small.unpersist()\n",
    "train_small.unpersist()\n",
    "test_small.unpersist()\n",
    "item_similarity_small.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2581f1-14ed-4e88-b27f-5a03b193b846",
   "metadata": {},
   "source": [
    "## Шаг 10. Масштабирование на полный датасет\n",
    "---\n",
    "*Моё \"железо\" не тянет выполнение следующего блока кода, поэтому выполнение этого кода пока что выключено...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b55a5d08-c534-4a9e-bd1d-91ef960901c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_on_full_dataset():\n",
    "    total_start = time.time()\n",
    "    \n",
    "    # Загрузка данных\n",
    "    data = load_movielens_data(DATA_DIR_FULL, spark)\n",
    "    validate_data(data)\n",
    "    ratings_df = data[\"ratings\"]\n",
    "    movies_df = data[\"movies\"]\n",
    "    print(f\"Размер: {ratings_df.count():,} рейтингов\")\n",
    "        \n",
    "    # Split\n",
    "    train_df, test_df = prepare_train_test_split(ratings_df)\n",
    "    test_df = test_df.cache()\n",
    "    print(f\"Train: {train_df.count():,}, Test: {test_df.count():,}\")\n",
    "    \n",
    "    # ALS CV\n",
    "    best_als, cv_model, cv_results = train_als_with_cv(train_df)\n",
    "    # Оценка ALS\n",
    "    als_metrics = evaluate_als_on_test(best_als, test_df, dataset_name)\n",
    "    als_ranking = compute_ranking_metrics_als(best_als, test_df)\n",
    "    \n",
    "    # Item-based CF\n",
    "    item_sim = build_item_based_cf(train_df)\n",
    "    itembased_rmse = evaluate_itembased_rmse(item_sim, train_df, test_df)\n",
    "    test_users = test_df.select(\"userId\").distinct()\n",
    "    itembased_recs = generate_itembased_recommendations(item_sim, train_df, test_users)\n",
    "    itembased_ranking = compute_ranking_metrics_itembased(itembased_recs, test_df)\n",
    "    \n",
    "    # Сравнение\n",
    "    comparison = compare_models(\n",
    "        als_metrics[\"rmse\"],\n",
    "        als_ranking,\n",
    "        itembased_rmse,\n",
    "        itembased_ranking,\n",
    "        dataset_name\n",
    "    )\n",
    "    \n",
    "    total_elapsed = time.time() - total_start\n",
    "    print(f\"\\nВремя: {total_elapsed:.1f} сек ({total_elapsed/60:.1f} мин)\")\n",
    "    \n",
    "    # Освобождаем ресурсы\n",
    "    ratings_df.unpersist()\n",
    "    train_df.unpersist()\n",
    "    test_df.unpersist()\n",
    "    item_sim.unpersist()\n",
    "\n",
    "# run_on_full_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b01d857-7d01-481a-bba1-c88de9a94f4a",
   "metadata": {},
   "source": [
    "## Шаг 11. Остановка SparkSession\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a412dbc3-b050-404a-be1f-21dc2ce5744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f9af55-fa14-4d75-83d1-bf910f2b17f5",
   "metadata": {},
   "source": [
    "## Выводы\n",
    "---\n",
    "В ходе работы были рассмотрены два разных подхода к построению рекомендательных систем: факторизация матрицы рейтингов с помощью ALS и Item-based Collaborative Filtering.\n",
    "\n",
    "Эксперименты показали, что **ALS** лучше справляется с задачей предсказания численных рейтингов. Более низкое значение RMSE означает, что модель точнее аппроксимирует предпочтения пользователей, используя латентные факторы. Такой подход хорошо подходит в ситуациях, где важно понимать, *насколько* пользователю понравится объект.\n",
    "\n",
    "В то же время **Item-based Collaborative Filtering** показал себя лучше при оценке качества самих рекомендаций. Более высокие значения ranking-метрик говорят о том, что этот метод чаще включает релевантные фильмы в топ-K рекомендаций. Это объясняется тем, что Item-based CF напрямую опирается на сходство между фильмами и эффективно использует популярные и часто совместно оцениваемые объекты.\n",
    "\n",
    "В итоге результаты подтверждают, что универсального решения не существует. **ALS** и **Item-based CF** решают задачу рекомендаций по-разному и показывают преимущества в разных сценариях. Выбор конкретного подхода должен зависеть от целей системы — требуется ли более точное предсказание рейтингов или качественные списки рекомендаций для пользователя."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
